
Thu Mar 14 07:17:11 EDT 2013

Thoughts...

The question is, when am I allowed to look at the bodies of an if or case
statement? For example, if I want to simplify:

    if p then True else False

 to just p?

The answer, from the semantics, is I'm not allowed to look inside the bodies
of an if or case statement unless there exists some assignment in the current
context under which the predicate dictates I'm allowed to look inside that
body.

In general I need an SMT solver to know this.

What this means is: IVP is not something we can rely on to make things
correct, because I can always come up with a more complicated example which I
need an SMT solver to figure out. The only thing IVP could be useful for is
slight performance improvements.

But, as currently implemented, it's wrong, because it looks at things it
should not look at.

If error is the same as non-termination, then I should be able to represent
Smten error as a haskell error. I should not need a separate ErrorEH for it.
If I do need a separate ErrorEH for it, that means I'm not being lazy enough.

The general solution, as I've said, is to use an SMT solver. I think this
would make Smten very powerful. We could handle this incremental stuff as is
supported by sketch. It would be very cool.

There is a concern about performance, but perhaps it is not a valid concern.
There is also a concern of: so far every SMT query is explicit. This
introduces implicit SMT queries, which the user may not like. So I feel like,
perhaps, there ought to be two modes? But that doesn't make sense, because the
other mode is not correct from a semantic point of view.

Anyway, IVP still has its use. I should think of it as an SMT cache, if you
will. It can answer all the easy questions about whether a predicate can be
satisfied in the current context. Only when it can't figure the result out
easily does it have to go back to the main SMT. I think this would be very
useful.

Another idea. Basically, we want to use the SMT solver as follows:

In a context, we encounter:
    if p
        then a
        else b

The question is two-fold

1. Is it possible for 'p' to be true? If so, we can look at 'a'.
2. Is it possible for 'p' to be false? If so, we can look at 'b'.

If we are looking at this expression in the first place, assuming we check at
every condition, that means there is a satisfying assignment so far, so at
least 'a' or 'b', and maybe both will be legal to look at. If I have a sample
assignment, I can just evaluate 'p' under that assignment to see which branch
it takes. That gives me a sample assignment for the first branch. Then ask for
a different assignment for the other branch. This way I only have to ask 1 SMT
query per branch, so the number of queries we ask is the same as the number of
branches. Maybe that's better, maybe it's just a small optimization.

You know, this approach is interesting, because I end up asking the final
question as follows:

Assert: is there any branch under which this evaluates to True?

So, basically, I'm just searching the expression I have, it can be depth
first, using the SMT solver to prune away invalid possibilities. As soon as I
find 'True', I am done. I've found a satisfying assignment. I need not do
more.

That's very cool, because it could save a lot of computation over what I'm
currently doing. And presumably it won't actually involve that much more in
terms of SMT queries.

So, the short of the matter is: I need to switch to this approach. I think it
will make everything better except for user control.... But really I'm not
asking any harder or more queries, just asking the overall query in pieces.

I should implement this first.

Anyway, that's good to know. In the meantime, let me figure out this sharing
bug, fix that, and start to work on some other bugs.

The bug: we loose sharing, suspected in case desugaring.

First let me find the place in the code.
Then let me write up an example in Share. We may have been hiding this because
of IVP.

Found it:

guardsM :: [Guard] -> Exp -> Exp -> Fresh Exp
guardsM [] y _ = return y 
guardsM (g:gs) y n = do
    y' <- guardsM gs y n
    guardM g y' n

Notice: 'n' is duplicated in both the first guard failing, and the rest of the
guards failing.

So, for example, I suppose:

x <- free
a <- free
b <- free
case () of
    _ | a && b -> 0
      | a && not b -> 1
      | not a && b -> 2
      | not a && not b -> 3 
      | otherwise = (x + x + x + x + x)

Question: does (x + x + x + x + x) get duplicated a lot?

Let's give it a try.

No, that's not the right thing. Because they don't chain...

I need there to be multiple ways for me to get to this otherwise.

Okay! I got it. Cool.

Now, let me fix the problem and verify all is happy.

That mostly fixes the problem. But we still loose sharing.

We have:

5 == if a then if b then if c then if d then 5
                                        else s
                              else s
                    else s
          else s    

This is turning into:

if a then if b then if c then if d then 5 == 5
                                   else 5 == s
                         else 5 == s
               else 5 == s
     else 5 == s    

The thing is, we don't share (5 == s), when we ought to!

In other words... Consider you have:

f (if p then if q then a else b else b)

When I push, I duplicate the application f b, without preserving sharing!

Note: this is in 'f', where 'f' is a primitive function.

Not sure how to deal with this.

Anyway, I found some more examples of lost sharing in Match.
    altM, mkcases, maltsM - args ?

How about I go ahead and fix them now? So long as we don't introduce bugs.

Aha! I see the bugs I've introduced. It's fine to declare a variable, but what
if the variable is part of a polymorphic declaration, so it's type is not
monomorphic, so we don't say what its type is, and we never end up using it,
so there is ambiguity?

Or, another way to put it: what if we never use the default? Then we shouldn't
create a new variable for it, should we?

This is something to figure out and fix. I bet this contributes more to
performance than other things I've been futzing with.

Thu Mar 14 09:04:28 EDT 2013

Okay! So some clarity from my morning walk:

* The bug is not in desugaring, it is Compile. Because anything desugar can
  write, I could write by hand and have the same problem.

* I should use a common function for sharing things in Match desugaring.
* It can check to see if the variable made is used, and if not, get rid of it
  right then. But that's just an optimization for later on.

Note: Sudoku2 has stack overflow without ivp. This could be related to the
stack overflow we get in arch_extract. But I'm going to ignore the issue now.

Thu Mar 14 09:13:45 EDT 2013

Okay, so now everything in case desugar shares. We just have a compilation to
Haskell issue with shadow:

shadow :: Integer -> Integer
shadow = \x -> (\x -> 2*x) (x+1)

Which compiles to:

shadow :: Integer -> Integer
shadow = \x ->
        let _s = (error (S.smtenHF "case no match"))
        in (\x ->
                let _s = error (S.smtenHF "case no match")
                in ((*) :: Integer -> Integer -> Integer) ((fromInteger :: Integer -> Integer) 2) (x :: Integer)
            ) (((+) :: Integer -> Integer -> Integer) (x :: Integer) ((fromInteger :: Integer -> Integer) 1)))

Thu Mar 14 09:45:02 EDT 2013

Problem is: _s is never used, so Smten type inference doesn't know what the
type of it is. So it is a bug in desugar. And a bug in the type checker for
not telling me about the ambiguous type.

Trouble in checking for "~44" in type checking: we don't call checktype in the
internals of Exp. I need to set up the type variable environment for that to
work right.

But this is the right approach.

1. Fix the type checker.
2. Fix the desugar.

We are not allowed to introduce ambiguous types. So... either I need to
somehow link the types of _s, or recognize that it isn't used, so don't
introduce it. I think I like the idea of the later.

Okay! So, question is, how can I do checktype inside of Exp? This is clearly
an issue for typecheck.

Okay, this is easy. I may want to clean up a little at a time.

First step:

TypeCheck should happen always in the context of:
  Type Variables (with kinds)
  Variables (with types)
  An environment.

So everything has the same form. Use it.

Sounds good to me. Let me work on this just a little bit. I have to get to
work on 6.375 stuff soon.
  
Okay, I have the test case for ambiguous types. Now to fix it.

First: reorganize type checking.
    
I think the proper solution would be for type inference to replace all
ambiguous type variables with UnknownT. That shouldn't be too hard to do. Just
enhance the assigns lookup function to check for '~'. Then in type checking we
get UnknownT?

Or! Only allow a variable type if that variable type is in scope! Of course.
Perfect. Easy. Wonderful. I like that solution best of all. Maybe a
combination of the two would make for the best error messages.

Thu Mar 14 11:04:02 EDT 2013

Okay, so there is some scariness here. I changed type checking, and now I
don't get a type error, but the haskell compiles fine. What??

Thu Mar 14 11:06:39 EDT 2013

There must be an issue with my makefile :(. Cleaned and recompiled, and now my
type checker gets the error. Odd...

Anyway... Having trouble now.

With type variables which are never used.

Hmm... There is an issue with shadowing. We might think something is used when
it isn't because it is suddenly shadowed.

Oh well. I'll fix that when I come to it.

Case desugaring: fixed.

Thu Mar 14 11:34:18 EDT 2013

This helped arch_extract. It's gotten a bit further. I want to see what
queries it is generating now.

There is still this sharing problem:

f (if a then (if b then x else y) else y)

Where 'f' can be: a primitive function, or a case.

Result is:
if a then (if b then f x else f y) else f y)

Problem is: we destroy sharing. (f y) and (f y) are not considered the same.

Note: I am allowed to look at 'y', because (f y) is case or primitive: it's
strict in its argument. So, I could preserve sharing if I cache these kinds of
things. I'm not sure what the right way to cache them is though. That's sad.

The idea is, we would like to share them at the Haskell level. Then all our
sharing mechanism kicks in.

Well... how about this. I know when I do this function pushing. That's when I
should make the cache.

Hmm... Is this really the problem though?

If I look at the generated query, aren't all the sharing violations simple
violations? There aren't any real big things, right?

The problem is, lots of simple things can add up to big things...

You know what I should do? Look at the desugared arch_extract, see if there is
any other problems introduced by desugaring.

It may also be good to work these queries by hand and understand where they
are coming from. Are they as big as we expect?

Why are we getting things like:
    case x of
       True -> True
       _ -> True

Shouldn't that not happen?

Hmm... Things to think about.

Thu Mar 14 12:51:25 EDT 2013

Okay, so I have an idea about how to make progress here.

Look at each individual assertion. Understand the high level code, then see
how it leads to the query it leads to.

Remember, the current issue is we are generating really really big queries,
which take a long time to generate and send over to the SMT solver. So, in
order to improve performance, we need to generate not so big queries.

Side note: Nirav had a suggestion for how we can compare two ExpH for equality
without forcing them. Instead of making EID part of ExpH, wrap each ExpH in a
record with an EID. That way we are basically identifying the thunk, even
before things are evaluated.

That makes sense to do, I think. It could clean up the code. I could also make
it slightly annoying, but maybe that's okay.

In the 5 minutes I have before I do class work, let me try to minimize the
first assertion, which is supposedly very simple.

Thu Mar 14 13:03:09 EDT 2013

More bugs in case desugaring I have to work out. Looks like we are dropping
things prematurely. Sadness. Maybe an issue with not producing fresh
variables?

Oh well. I'll have to look into it I suppose. I have a fairly simple failing
example.

When I come back.

Thu Mar 14 13:33:23 EDT 2013

Nirav pointed out another thing:

Say we have:

let y = case x of
          Just v -> e1
          - -> e2
    z = case x of
          Just v -> e3
          _ -> e4

In order to execute the case expression, we need to compute isJust and
validValue. The current implementation pushes the case inside of 'x', and
replicates it for each branch of 'x'.

I was proposing that instead of pushing the case inside of 'x', we just
traverse 'x' and figure out directly.

From previous discussions, it was proposed that we make a different
representation for 'x' which, in effect, caches this traversal. The above
example shows why caching the traversal could be better than replicating the
traversal. Especially because these symbolic things could be nested, so
redoing the traversal could lead to exponentially more work than we want.
Caching is like a dynamic programming approach.

Well, that's a pretty solid motivation for changing the representation of
symbolic, user defined datatypes.

But perhaps it also suggests an alternative implementation, which is we just
add a cache to symbolic objects (ExpH). You want to test for a constructor, we
may have already asked, in which case we can reuse the previous result. An
IORef like approach is possible. A pre-cache is also possible, where we create
the full table (lazily) as soon as we create the ExpH.

I'm not sure if this addresses the query size issue. For that I need to do
what I was planning before. But I need to fix the bug first. When I come back.

Thu Mar 14 14:14:13 EDT 2013

I have minimized the bug, so it should be easy to figure out:

foo :: Bool
foo = let { (x :: Bool) = null "a" } in x

It looks like you have to have the type signature on 'x'.

What happens to this?
ldecls, and we call letPE.

Looks like we have: LPat (x :: Bool) null "a"

So we call:  letPE (LPat (x :: Bool) (null "a")) "x"

So we call: mletsE (lcoalesce 

So we call: mletsE (x, null "a")

So we call: mletE x (null "a") 

So we call: mcaseE (null "a") [simpleA x x []]

We call altsM on that. 

We call sharedM to share (null "a"), because we will do a case on it. Makes
sense.

n' is error case no match

x is not simple, so we will share. And call

s = null "a"

altM s (Alt (x :: Bool) (WBodies [Body [] x] [])) n'

n' is simple, so we don't share now.

body <- wbodiesM (WBodies [Body [] x] []) n'
patM s (x :: Bool) body n'

bodiesM [Body [] x] n'
bodyM (Body [] x) n'
guardsM [] x n' --> x

patM s (x :: Bool) x n'

Which is:
  case s of
    x -> x
    _ -> error

Turns into...
  appE (\x -> x) s

Which is:
    let x = s
    in x
 That's correct...

So, the result of the altsM thing is:
    let x = s
    in x

Now I ask, is 's' free in that? The answer is yes! What's the problem here?


Let's assume things go in order, and do some debug traces.

Is it a types issue? That's an interesting question.

Thu Mar 14 14:44:20 EDT 2013

Okay, here's the deal. You give 'Bool' explicitly as the type. Bool and
UnknownT are not equal, so we weren't finding the match.

Thu Mar 14 14:48:33 EDT 2013

Now, looks like the first assertion is simple. isCF a b.

Let me see if I can reproduce the fun.

Okay! We get quite the query generated by isCF. Let me see if I can understand
it. (So much for class work...)

The strategy is simple. Create a free state. Apply (r2 ; r1) and (r1 ; r2) on
the state, assert the results are not equal, query the state. Simple. So how
did it get so complicated?

We have a bunch of registers and free fifos. The instance of Free is
autoderived for the state, which should do the right thing.

Applies does what you expect: apply the rules in turn, with explicit bind for
Maybe type.

Apply applies the rule function, converts the tuple (True, v) to a maybe type.

Everything looks simple in this example. Why do we get such a big query?

Let me do it by hand and see what I get.

s = MOD_mkTest
    { inst_x = MOD_RegN f1,
      inst_y = MOD_RegN f2,
      inst_z = MOD_RegN f3,
      inst_a = MOD_RegN f4,
      inst_f = MOD_FIFO2 {
            arr0 = if f5 then Nothing else Just f6,
            arr1 = if f7 then Nothing else Just f8 }
      inst_g = MOD_FIFO2 {
            arr0 = if f9 then Nothing else Just f10,
            arr1 = if f11 then Nothing else Just f12 }
      inst_h = MOD_FIFO2 {
            arr0 = if f13 then Nothing else Just f14,
            arr1 = if f15 then Nothing else Just f16 }
}

That's exactly right. Good.
      
Now, if I apply ra to that, what do I get?

What do I expect?

Guard: 
 meth_i_notFull_FIFO2 && meth_write_RegN x && meth_enq_FIFO2

Okay, so that's a little bit weird. But in other words:
 arr1 is Nothing or arr0 is Nothing

Value:
Original state with:
    New value for x: x + 1
    Update f:
      arr0: if f_empty then x else what it was
      arr1: if f_empty then Nothing else x

What do I actually get?
      
x = f1
f5 = isJust arr0
f6 = fromJust arr0
f7 = isJust arr1
f8 = fromJust arr1

I get:

Guard:
(if ((if f7 then 1
            else if f5 then 1
                       else 0) == 1)
    then  if (if f5 then True else True)
             then True
             else False
    else False

This is good. What does it say?

Guard:
  (f is not full) and (??)

Where does this if f5 then True else True thing come from? 

if f5 then True else True is guard1. I'm not sure why. Let me look closer.

Oh. This makes sense. The guard is from the meth_enq_FIFO2, which says:
In the case of f5, True, otherwise True.

So this makes perfect sense. I don't expect to be able to recognize this
sharing. Good. I'm happy then. The guard makes sense. And the last nest is
because we do: foo && True.

Aha. So the issue here is, the way the code is written, to know the guard for
FIFO_enq depends on whether FIFO has one element or not. This creates a false
dependence. I could probably hand optimize the code to lead to a much better
query. And this could lead to big differences as we glue things together.

Now, for the new state.
I expect x is f1+1.
I expect f is: if f5 then arr1 is f1, else arr0 is f1

I get: x is f1+1     good!
I get f is:
    if f5 then FIFO (Just f1) Nothing
          else FIFO (if f5 then Nothing else Just f6) (Just f1)

This is good. Why the extra check for f5?

I had:
    arr0 = if f5 then Nothing else Just f6... Oh, so that stays the same.
Makes sense!

Inferred value propagation would be nice to have here.


Hmm... I wonder. I bet by changing minor implementation stuff, these issues
would go away. Now, you could imagine the user doesn't want to have to
nit-pick these little things. But I think it would be interesting to see the
effect they have on the overall arch_extract tool.

We said the following:
 * enq_FIFO2 should always return True for the guard, regardless of anything
   else.
 * enq_FIFO2 should change arr0 as soon as it knows more info about it.
        (explicit inferred value propagation)

Let me try these and see.

Wow! It goes much faster now in the initial queries.

We still get stuck at this big (9, 4). Memory totally blows up then.
But this is good progress. I feel like I ought to keep looking into these
things.

It's a different question whose responsibility it is to make these changes.
The user or the compiler?

Thu Mar 14 20:46:12 EDT 2013

Question: Do we need AppEH?

The reason we used to have it was when we had support for primitive free
functions. But I don't have that anymore, right? So I should be able to get
rid of this.

And clean up the SMT syntax while I'm at it I suppose.

Let me try this.

Thu Mar 14 20:58:29 EDT 2013

Got rid of AppEH.

Can't so easily get rid of caseEH. Because we might have one.

Not unless I change my scheme from case pushing to extracting tag and args. My
'iffy' scheme.

Let me look back in my notes to see whatever it was I did to that.

Thu Mar 14 21:11:13 EDT 2013

I saw my notes. This is not a task to try to do tonight. It is much more
involved. Let me instead work on other cleanup tonight.

Thu Mar 14 21:21:20 EDT 2013

I don't know what else to clean up. So how about instead I go back to work on
understanding the arch_extract symbolic computations.

* free s - check
* rule a applied to s - check
* rule be applied to s

What do I expect?
 f better not be empty
 f is dequeued
 g better not be full
 g is enqueued with the value of y
 y gets y + x

So, I would expect something like:

(if f5 then 1 else if f7 then 1 else 0 == 1) -- f is empty
&& (if f9 and f11 then 0 else 1 == 1)        -- g not full
&& True                                      -- g can enqueue

And this is what I get. As expected.

And the value?

y: f2 + (if f5 then f6 else 0)
f: arr1, Nothing
g: as expected

Okay, so y is close, except we have an extra layer I don't expect.
f is as expected.

That was from the implementation of fromMaybe, which I cleaned up
slightly.

It looks good. Good.

I feel like that's about as much simple stuff as I can do. The next thing I
need is to apply a rule again.

It's probably worth doing though.

I wonder if the issue is this. We start with a free state which has conditions
in it: if p then a else b. We feed it through a function which does different
things based on the conditions, leading to more conditions. Then again, and
again, and again. Doesn't this cause the expression to blow up?

For example, what if I applied the rule 'a' over and over and over and over
again on the free state. Would it not get really really big?

In fact, I can start by just looking at the guard. This is a worthy
experiment. See if I can get exponential blowup this way. If so, then I'll
have an idea what the issue is.

Yes. It's worth understanding repeated applications of rule 'a'. What does
that lead to? And why?

It doesn't seem to scale badly. But there is still some fishyness I would like
to understand at a deeper level. Tomorrow perhaps.

One thing I can think about over night, hopefully, is what happens when we
have 

f (if a then if b then if c then if d then x
                                      else y
                            else y
                  else y
        else y
)

Both when 'f' is a primitive function, and when f is a case. Or, in other
words, when we do 'pushfun'.

Perhaps all I need to do is push the function down into everything all at
once, and maintain sharing when I do so.

