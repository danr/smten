
Tue Aug 14 08:59:05 EDT 2012

nheap is slow because of searching for free variables and alpha renaming. The
problem with doing a uniquification pass is, I fear, it puts a sequence
requirement on elaboration which I'd rather not do.

There is a way, I think, I could get away without the uniqification pass,
without alpha renaming, and with sharing of reductions. You have a scope, for
beta reduction, you just put the argument in scope and elaborate the body
under that scope. We make sure everything on scope is elaborated. Now, when
you get to a variable, you can look it up in scope. If it's simple, inline it,
if it's not simple, then don't inline it.

The key thing for alpha renaming is: never try to elaborate a variable
referred to on the scope under the scope, because the meaning of the variable
could be from a different scope.

Things we do to reduce:
- beta reduction: just put the argument on the scope after elaborating it.
  Easy.
- primitive literal operations: literals will be inlined, so that's fine.
- primitive bit operations: we can have a special case to inline bit vectors.
- pattern matching: var, wild, integer all are easy. The trouble is with
  constructors...

Say we have something on scope:

foo: Blah a b c

Where a, b, c are free variables which could belong to another scope.

Now we want to pattern match against this, say: Blah _ v _. So, you could say,
yes, clearly this is a match, and now add to scope v points to b. The problem
is, we don't know which b v is referring to? Is that really a problem?

I should think about this more. I think this has potential to really speed up
the non-heap elaborator, which, I think, honestly, is a lot more promising at
this point than the heap elaborator.

Another thought on the heap elaborator. We could make heapify pure if we
wanted by having references be ST computations which return expressions rather
than STRefs. You don't perform the computation until you need to. That could
give us the sharing we want.

I had another, little idea I want to try out with the nonheap elaborator. For
case matches, which takes up, if not a whole ton of time, some bit of time.
Unfold the expression for a constructor match. Match the constructor (or not),
then match each sub element. That way, at least, it should be obvious...

Wait, the real question is, do we need this check for iswhnf. Because, if it
is whnf, wouldn't it have already failed?  That's worth checking.

Like, if we assume it's well typed, which I think is fair to do... then iswhnf
does nothing, right? Let's look at the cases where it is true.

1. LitE. Then the pattern is IntegerP, and I added a case to detect that
failure.
2. LamE. Then the pattern can't be LitE or ConE, so it must have matched.
3. iscon: it must have been a constructor, and I added a case to detect that.

Tue Aug 14 09:36:47 EDT 2012

Okay, so I simplified the pattern matching. Profiling says it takes more
memory, and noticeably less time (gar).

Let me pursue this question about shared reduction/alpha renaming.

The main cost we have is asking if we should reduce an expression. This
requires looking up the free variables in the argument.

After that, alpha renaming is rather expensive.

I suppose I could focus on alpha renaming performance, try to improve that...

Tue Aug 14 10:27:52 EDT 2012

I tried to improve it. No progress. Blah.

Clearly the thing to improve with the nheap elaborator is the shouldreduce
predicate. In particular, the case where we check to see if there are any free
variables in the argument to be careful about.

Tue Aug 14 10:47:14 EDT 2012

Just an update:

nheap on BCL3 with 9 queries:
 no profiling compiled: 4.4
 run in yices: 1.7

So we are within a factor of 2-3.

I feel like we could improve that, but it will be complicated and lead to not
very great improvements. I also have to worry about the infinite elaboration
bug.

Let me take a closer look at the generated query, see if there is any sharing
I expect to see that I'm not. Why is the query so darn big?

Tue Aug 14 11:18:42 EDT 2012

Looks like the query is so big because we do a lot of repeated applications of
a complex function to different arguments.

But! I did an experiment with errors. If we assume no errors, the yices query
is 2/3 the size, takes half the time to run in seriq2, but takes almost an
order of magnitude less time in yices (5x improvement)... This could be
important.

And then, elaborate really becomes costly in seriq...

Note: with yices1, we should be able to make very simple queries by taking
advantage of lambdas. Perhaps we could get back to what Myron wants...

Hmm... what to do about this error thing...

Tue Aug 14 11:47:49 EDT 2012

I think it would be nice to have a runtime option for it. Let me add that in.

Tue Aug 14 12:22:42 EDT 2012

Okay, I want to spend some time now diving deep into a proposed new
elaborator. Based on the nheap elaborator, but using a scope to hopefully make
reduction much cheaper and avoid any need for alpha renaming, the two things
which are slowing nheap down the most.

But I want to try and understand this from scratch, rather than a modification
on the previous attempt.

Let me start by ignoring case statements and pattern matching. Get functions
and reduction to work first.

Let's also distinguish between elaboration modes:
 WHNF - don't traverse into bodies of lambdas or alternatives
 HNF - do traverse into bodies of lambdas or alternatives
 S - share complex expressions wherever possible.
 NS - don't share complex expressions.

The difference between S and NS is, I believe, a post processing step. The
difference between WHNF and HNF is obvious during elaboration. The two kinds
of modes are, I believe orthogonal.

What's more, I feel like the only difference between S and NS that matters to
us is, well... honestly? Perhaps none. We could just have our elaborator
produce a sharing elaborator. So don't worry about that distinction at this
time. In particular, favor sharing whereever possible.

Good.

A big part of my new proposal is to have a scope. Let's assume a scope
structure, mapping names to elaborated expressions.

Elaborate will take as input... or ideally just have in a closure somewhere,
the mode of elaboration and the environment. No need to be passing those
around recursively anywhere. It will take a context, which does need to be
passed around, and the expression to elaborate.


How to perform elaboration:
- LitE
Trivial. It's elaborated. Done. Easy.

- CaseE
I'm not going to worry about this yet.

- AppE
1. elaborate the function to WHNF (not Full!), haskelly lazily.
No need to elaborate the argument yet.
Cases:
 - function is Seri.Lib.Prelude.valueof: return the appropriate integer.
 - function is a unary primitive:
     like __prim_zeroExtend_Bit, __prim_truncate_Bit
     Elaborate the argument fully, haskelly lazily, and get its value.
     Apply the primitive if the argument is reduced enough.
     Otherwise: ...

This brings up a first important point. What if we have a VarE argument to a
primitive, which points to a primitive?

Options: have it elaborate to the primitive, that's fine. No problem there. So
there is no special case here to worry about.

    Otherwise: Return the application of unary predicate with elaborated
    argument.
    
 - function is a binary predicate.
     elaborate first argument as much as possible.
     if it's elaborated enough:
        elaborate second argument as much as possible.
            if it's elaborate enough: apply the primitive.
            otherwise: return application with as elaborated as we have
     otherwise:
        if WHNF: return application with as elaborated as we have
           HNF: elaborate second argument as much as possible,
                then return application with elaborated args.
     In particular, the choice here is: if the first argument isn't elaborated
     enough, don't even attempt to elaborate the second. Aha! But we should if
     we are doing full elaboration.
 - function is a lambda
     1. elaborate argument as much as possible.
        Note: we aren't really being lazy here. But this is how we get our
        HOAS-like sharing, so I think this is important.
     2. put the argument on scope: mapping name to value.
     3. elaborate the body under the new scope.
     4. if we should inline the argument, inline it,
        otherwise: return the application of elaborated arg to lambda.

        When we should inline it:
           - when it never appears in body (MUST)
           - when it appears once in body, if it won't be captured (MAY)
           - when it is LitE, ConE (MAY)
           - when it is VarE, if it won't be captured (MAY)
    
        Question: what if the type of the argument is a function lambda? For
        yices, do we want to inline that too?
    
        Note: we can allow inlining which will be captured if we perform
        renaming.

        Lot's of choices here, which could impact things.

 - else: if WHNF, return application of elaborated function to unelaborated arg
         if NF, elaborate arg, return that application.

Question: do we need to push applications inside lambdas? Or is that somehow
taken care of already? This is a yices specific thing. The goal is to always
have fully applied primitives and such.

Consider the following example:

((\a -> (\b -> a+b)) x) y

How does this fully elaborate?

Application, start with argument
Application, start with argument
Lambda: go inside.
Lambda: go inside.
Nothing we can do.
Application:

hmm... now it seems a shame here, to fully elaborate inside before doing the
application. Because we go all the way inside, find we can't do more, then go
back inside to do the application.

The reason for this is: what if the function is shared?
If it's shared, it will already have been fully elaborated, because the only
way we can get sharing is through application, where the argument is already
evaluated. Thus: only weak head elaborate the function to an argument!

This suggests we will want to pass around the mode as an argument to
elaboration, so we can change it to WHNF for this.

Question: what if the lambda in WHNF has some sharing? So it doesn't look like
a function? What if it's a variable, for example?

Let's look at the following cases, for example:

1. ((\a -> (\b -> a+b)) x) y
2. (let a = x in \b -> a + b) y

1.
function is in weak head normal form. Elaborate x, say to x, add to scope,
elaborate:

a: x
\b -> a + b

We may or may not inline. Let's say we don't.
This is as elaborated as we'll get.

Result is... just like (2). The function is not a Lambda, but only because of
sharing. What should we do here?

Options:
- don't share. Force true WHNF, then do application.
But that's bad, because x could be really complicated, and appear multiple
times, so we don't want to duplicate it.
- go inside the sharing.

a: x
(\b -> a + b) y

a: x
b: y
a + b

Which is what we want. So yes, we want this kind of a rule.

Any concern about name capturing issues?
What if our argument refers to a free variable? Can that be captured?

Answer should be: no, the argument is fully elaborated?

Consider, for example:

\a -> ((\a -> b) x) a)

We go inside. We push. We get:
\a -> ((\a -> b a) x)

This is wrong!

That's bad.

Oh. But maybe this isn't a problem?

Except that, we don't have a name to give a.

Hmm... This is trouble some. But it is giving me another idea.

What if we do application like follows:
1. Elaborate the argument, push it on a stack.
2. Lambda adds mapping from name to stack location.

Primitives: read stack?

Erg. I'm not sure that makes any sense.

I feel like this is a problem of delambdafication. Perhaps delambdafication
should be a separate step? Not part of elaboration?

Then we can share lambdas and not worry about this kind of thing.

Okay, let me push on then, if I can. Assuming we'll make delambdafication
another thing?

Maybe I should figure out how to implement the delambdafication phase first?

Let's push on with elaboration. I want to figure out how things will work.

- LamE
If WHNF mode, do nothing.
Else: add to scope: n => VarE n, elaborate body under new scope
      return a lambda with the elaborated body.

- ConE
return as is.

VarE
- if nullary primitive, deal with it.
- if in scope and simple, inline it.
- if not in scope, but in env: look it up in environment, return elaborated
- else: return as is.

Okay, so that's the meat. We should be able to ask about alpha renaming, then
about case statements.

Alpha renaming case:

\b -> (\a -> \b -> a+b) b

b: VarE b
a: VarE b
b: VarE b
a+b

Turns into:

\b -> let a = b
      in (\b -> a + b)
          
Which is, rather, the same as before. But it looks right to me. We don't have
a name capture problem.

Okay, fine. Now, how do we deal with case statements?

Elaborate the argument fully first.

For a given match:

VarP: matches, just turn it into a lambda.
WildP: matches, just ignore the argument.
IntegerP: either matches fails or not.
ConP...

We have to look up in scope, because it's not going to elaborate? Why not
allow it to elaborate? It could have some sharing in it.

let foo = blah
in Foo foo foo

But that's not a problem, really. I say inline constructor applications like
this.

The concern is, one of the arguments could have a free variable which will be
captured. Will I ever try to elaborate it? The free variable?

I think the answer is no, so nothing to worry about here?

Well, the real question is, when do we ever try to re-elaborate something?
Just after lookups, so this shouldn't be a problem.

Why is alpha renaming currently a problem, and what about what I've done makes
it go away?

\b -> (\a -> \b -> a + b) (Foo b b)

\b ->
    (\a -> \b -> a + b) (Foo b b)

\b ->
    \b -> (Foo b b) + b

Um... that's a problem. The only reason it isn't a problem is if I only do the
lookup for a case match. Because then we only make references to parts of the
expression, we don't inline it.

So, I feel like a more general solution is: have a way to look up the unshared
version of an expression, used in pattern matching and primitive reductions.

\b -> (\a -> \b -> case a of {Foo v _ -> v} + b) (Foo b b)

b: VarE b
a: Foo b b
b: VarE b
v: VarE b (wrong one!)

Nope. This won't work.

I'd like this to elaborate to:

\b -> (\b1 -> b + b1)

The only way that can happen is if I give a new name to something.

So, we could give new names when we go into a lambda, if something is already
in scope?

\b -> (\a -> \b -> case a of {Foo v _ -> v} + b) (Foo b b)

b: VarE b
a: Foo b b
b: VarE b'
v: VarE b
in b' + b

But this only works if I actually inline the second b...

Hmm... so, maybe I can try to adapt my existing algorithm to do this lazy
reduction and renaming. Rather than start from scratch all over.

How does it work?

We pass around a scope.
Lambda reduction just adds to the scope. But, it makes sure to add a fresh
name to the scope. So, if 'b' is in scope, and the lambda expression is for
'b', well, then, we say anytime from now on we see 'b', inline it as 'b1'.

Any time we see something that referred to 'b', we'll just inline it once, and
so it will be right.

So, we pick new names when we need to because something is in scope. All names
in scope (on the left hand side) will be unique? No. That's not true. But
we'll have shadowing, and keep them straight some how. Always inline VarE if
it is in scope. That's just doing our beta reduction... Oh. Wait. Only inline
if we should reduce? I can leave that unchanged for now. We still pay for
looking for free, but reduction is cheaper, and alpha renaming is cheaper.

Function arguments should go to WHNF, not full, right? yes, because we
elaborate them after reduction anyway.

That, at least, sounds like a reasonable plan to me. This is complicated,
sadly, so I don't know if it will work, but I can make progress at least, no?

It would be great if I could separate out delambdification...

Tue Aug 14 14:17:11 EDT 2012

Okay, here's the plan.

1. Try to clean up the nheap elaborator as much as I can. The easier it is to
understand and change, the better.
+ Elaborate functions just to WHNF before applying the lambda, not full
  elaboration. This should fix the array bug. I will be interested to see how
  it affects performance.
- make delambdafication a separate step if reasonable.
- make primitive elaboration more lazy?

2. Pass around a scope. Use this for reductions and renaming. Change nothing
else.

This should simplify the code a bunch too, I hope. That will be good.


Tue Aug 14 14:37:28 EDT 2012

Elaborated functions to just WHNF before reduction: made a huge difference.

In fact, now things besides elaboration are starting to pop up. Namely,
monomorphization. It might be worth taking a look there, to see if we have a
space leak or anything in monomorphization. Anything easy to fix.

High level profile summary:

elaborate:      32.5   36.4
check:          23.2    0.0
monomorphize:   11.9   26.2
runCmds:        11.9    8.3

Tue Aug 14 15:15:42 EDT 2012

Can my plan for reduction and alpha renaming actually work? I fear it may not.

Tue Aug 14 15:19:49 EDT 2012

First, how about I try using primitive yices booleans, rather than boxed ones?
How hard would that be?

No need to box booleans.
Define True as true. Define False as false.
Define True? as ... err, I dunno.

I could try it, see what happens, what issues come up.

Tue Aug 14 15:38:59 EDT 2012

Looks like that helped yices a whole bunch (1.5s -> 1.0s). So now the
elaborator is even more of an issue, and yices even less of an issue. Sigh.

I should note: I thought we fixed the array test case, but it's still got some
bug somewhere. Just a different one from before, I suppose.

Should I try and figure out what the bug is and fix it?

The answer is: yes! I should. It shouldn't be too hard to figure out, eh? It
would be really cool if I didn't have this bug to worry about.

Tue Aug 14 16:18:42 EDT 2012

Anyway... what's next? Separate out delambdafication?

How does delambdafication work?

So, we have things in a sharing form. It needs to do the following:

- push application inside lambdas where possible (renaming as appropriate)
- push application inside case where possible (renaming as appropriate).
- perform beta reduction on function type arguments.

Can I make it separate? Or do they need to be together?

I should be able to make it a separate pass. It should be a separate pass,
because this has nothing to do with sharing. It's a kind of anti-sharing. So,
let me see if I can make this work.

Tue Aug 14 17:33:57 EDT 2012

Wow. Delambdafication as a separate pass actually works. That surprises me.
It's a good thing though. It should be separate. And hopefully it can make
easier both delambdafication and elaboration.

Tue Aug 14 17:39:51 EDT 2012

Okay, so, now I have this.  Can I make either elaboration or delambdafication
easier? I feel like delambdafication would be a good place to try and start,
because it's so much simpler, but has the reduction and renaming I want to get
rid of.

Tue Aug 14 18:43:38 EDT 2012

I had a thought. I shouldn't have to do any alpha renaming in the elaborator
now, because I'm not inlining functions which could contain free variables. 

Currently the only things I reduce which have free variables are VarE. This is
to avoid sillyness like:

let a = b
in a a a

Which is just as well written as: b b b

But! I bet we gain more from not having to do alpha renaming than the cost of
an extra variable.

Also, we could add a special case to reduce which does the reduction of the
variable as long as there isn't a naming conflict. Then, in most cases, we
avoid that issue.

I'm so going to try this.

Okay, looks like we run into a bug in the delambdafier. That's okay. I can fix
that.

Odd. It claims to be slower. Like somehow delambdafication has to do more work
then?

Let me try the special case for reduce, see if that helps any.

Um... special case for reduce has the problem that it will lead to infinite
elaboration.

Tue Aug 14 18:59:59 EDT 2012

Oh well, back to the drawing board I suppose.

Tue Aug 14 21:34:11 EDT 2012

Tried inlining reductions into delambdification. It didn't really change
anything, which I suppose isn't surprising, considering how little reductions
cost us in delambdification. There the whole thing is alpha renaming.
