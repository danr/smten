
Sat Sep 22 08:56:57 EDT 2012

I think I've come to some important observations about sharing.

I think sharing the way I've proposed it will not work. That is, general
purpose sharing, where we just stop elaborating if we see an opportunity to
share. The problem is, this has no regard for what can be simplified or
reduced later on. We'll share lists, queries, anything.

That's not what we want. What we really want is: elaborate everything fully as
much as possible. Then, from whatever's left, recognize what is shared. This
is why we first switched to the heap elaborator idea. That's sort of how it
works.

Okay, well, really there are two kinds of sharings I want to distniguish
between:

- Sharings within assertions.
Assertions are the only large expressions passed to yices. We want to fully
elaborate the assertion predicates, then share what's left to be shared.

- Sharing across assertions.
If you have a complex expression shared across assertions (as Myron does for
BCL3), you want to define it as a top level variable.

I think the first one will be much easier to figure out, and I should probably
focus on getting it right first before attempting the second. The second will
be doable, perhaps... but after more insight.

So, start with the first one. One way to look at what I want to do is: fully
inline and elaborate an expression, then do common subexpression elimination
to identify the sharing. The value of this is, it's fully inlined, and we get
full sharing back. The downside is, I suspect it will be terribly costly to do
full common subexpression elimination.

But, it's a good starting point, and perhaps worth a try, because if it does
turn out to be not so bad...

We have to remember the purpose of sharing. It's to improve performance.
That's it. So any sharing technique I identify will have to improve
performance over not sharing.

Anyway, I think it's worth trying common subexpression elimination. This could
be useful for seri in general to have lying around. But I don't expect it to
be a viable final solution. It may give insight into things.

The real dream is... we know potential sharing opportunities based on the high
level expressions. Any time we inline a variable or do a beta reduction, we
have information linking together multiple expressions as shared.

So, imagine, for example, we had some way to annotate expressions with
additional information. What if, every time we do beta reduction, we annotate
each expression being reduced with some unique ID. For example, in share:

quadruple a = a + a + a + a

assert (quadruple (quadruple (x+y)))

After partial inlining becomes...

assert (quadruple ((1: x+y) + (1: x+y) + (1: x+y) + (1: x+y)))

After full inlining becomes...

assert:
  (2: ((1: x+y) + (1: x+y) + (1: x+y) + (1: x+y)))
+ (2: ((1: x+y) + (1: x+y) + (1: x+y) + (1: x+y)))
+ (2: ((1: x+y) + (1: x+y) + (1: x+y) + (1: x+y)))
+ (2: ((1: x+y) + (1: x+y) + (1: x+y) + (1: x+y)))
    
Now common subexpression elimination for this is much easier, because the
candidates are all labeled. Perhaps I can use Nirav's tying the knot thing.

Here's how it works. We go through the expression. Any time we encounter an
annotation, we add it to a table with the value of that annotation, and
counting how many times that annotation is encountered. At the end, we want to
share anything that is encountered multiple times. We can do the replacement
while we do the count via tying the knot.

That way, common subexpression elimination becomes a single traversal, and we
only have to traverse common expressions a single time.

In fact, the job of common subexpression elimination could be to generate
these annotations in the first place.

You know what's the worst part? If we had access to the GHC pointers, we could
piggy back off those, because the sharing is already there. Just ask which
pointers are the same, use those as the annotations. Is there a way to do
that? It's rather hackish, I know, just ... wishful thinking I suppose.

Because somehow I need a way to annotate expressions otherwise. Which means
changing the definition of Exp to be something unpleasantly more complicated.

But, on the other hand, it is the case that annotations for expressions would
often come in handy. Like, this comes up over and over and over and over and
over and over again.

It would be useful for a bunch of stuff. Source code locations. Caching
variable uses. It's just not quite clear how to organize that and manage that
information.

GHC pointers are a bad idea. With GC and such these will move around. So
scratch that thought from my mind. We need to do this in the language.

Perhaps we could have a parallel structure on the side to keep track of this
info, but it seems like that would be rather difficult to keep in line with
the expression.

So, options seem to be:
- Make Exp and everyone who uses it parameterized by some attribute type 'a'
Then anyone who wants to put in an attribute can. I worry it won't compose so
well.

- Add a known attribute type A to each Exp.
This could either be something we agree upon that everyone knows about and
uses. For example, it could have a field for source location, a field for
expression identifier, a field for access. Whatever. The problem with that
is, you have to change A every time you want to add or change an expression,
which... ug. I don't like it.

Or... have a map of dynamic attributes. Map from attribute name to Dynamic,
and use some module based prefix to avoid name clashes.

That gives you the flexibility, while also letting you avoid collisions by
different modules.

There will be a cost to accessing this attribute map...

I don't know. It's a little bit scary to me.

I really hate Haskell's type class realization. This sort of thing would be so
much easier if there was a notion of a java-like interface and object.

Anyway, I need to think about this a bunch, so I'm going to think about it a
bunch then get back to you on my decision.  Then try it out. Perhaps it's
worth trying common subexpression elimination (which really isn't so hard:
just have a table from subexpression to unique ID, traverse the expression
updating that table, at the end you're done, everything is annotated just how
you like). Hmm... that suggests that CSE is... well, you have a hash table,
then if there are N subexpressions, of depth M each, then M*N. Actually,
that's really not so bad, is it.

Hmm... That suggests, perhaps I could just do CSE? It's worth a try anyway.
Then maybe I don't need an attribute. And I could try out tying the not?

Except, you would really like it to be a bottom up kind of thing. Perhaps I
could arrange for that too.

Sat Sep 22 10:29:51 EDT 2012

Okay, so, working out the crazy, tying-the-knot scheme for common
subexpression elimination.

I want a function, which behaves as follows...

Inputs:
- A mapping from common expression to name for all common
subexpressions. This is the result that we are passing in as input.
- An expression on which to perform common subexpression elimination.

Outputs:
- A new expression with common subexpression elimination performed on it.
- The set of all subexpressions in that expression which are available to be
  common (aka, they don't depend on a locally defined variable).

Err... I don't think the tying the knot thing is going to work. Perhaps I
should start by thinking of doing this in two passes.

Yes. That will be better. And anyway, two passes isn't so bad, is it?

So, change it to:

pass1: given an expression, return an expression which has no common
subexpressions in it, and a set of expressions available to be common (they
don't depend on a local variable).

pass2: given an expression, and a mapping from common subexpressions to names,
replace every occurrence of a subexpression in the list with the given
variable name.

And, like I say, if I'm clever, maybe I can combine the two passes into one,
but don't worry about that now.

The implementation of pass2 is trivial. No need to worry about that.

Here's how we do pass1:

For LitE, ConE, VarE, just return yourself, with a singleton set with
yourself. Easy. Actually, you can return yourself with an empty set.

For AppE...

Just for clarity, let me assume only a single argument.

Apply pass1 to both arguments.
You get back new expressions, and a set of common expressions for each.

Take the intersection of these two sets. Anything in the intersection is
common. Make up names for these common subexpressions, wrap the expression
around a let statement, and apply pass2 to each to do the substitution. Return
that expression, and for the set of available...

Return the union of the two sets + yourself. Easy!

And it extends in a naturalish way to more arguments. I just have to do
pair-wise intersection. Or perhaps nicer would be a way to count how many
occurrences each subexpression has, drop those with only 1 occurrence, and
what's left are the ones to make common subexpressions. Yes, that's fine.

Now, for LaceE...

Well, we'll do pass1 for each Match, and treat it like AppE. No problem.

Now, for Match: do CSE for it's body, then remove from the set of CSE any
expression which has one of the given bound pattern variables as free.

And that's it!

Simple. Straight-forward. We get nesting. No need to worry about things not
being in scope. It will do a fine job. I should totally implement this.

After I do that, I should ask if I can tie the knot. That is, merge pass1 and
pass2. It would be nice if I could, because we reduce the complexity. We have
just a single traversal, right? I bet that would work...

Wow. This could actually be an effective way to do CSE. Especially with tying
the knot, if that can be made to work. It's just a single, linear traversal
like thing.

Good. Let me implement it as its own target. It can be useful for whatever
reasons. It will operate on Exps. Somehow we'll have to come up with fresh
variable names, which is potentially annoying, but fine.

Sat Sep 22 14:21:39 EDT 2012

Some thoughts... I have to worry about naming. I need to pick a consistent set
of new names so that we don't have to recognize alpha-equivalent things.

So, return a map from subexpression to list of names which would be captured
at that point in the expression. Then just pick the first name from a fixed
scheme that doesn't belong to that set. So long as I always do that... one
would hope I would be okay?

Erg. It's not clear. It's fuzzy.

This is why it really would be nice if I could get potential common
subexpressions and names to use for them from the elaborator. Perhaps the
elaborator can just build up a table of the expressions it inlined and what to
call them? I don't know.

But! I got started thinking about names, and as we know, FreshFast takes up a
bunch of time in the profiler. And I really feel like it shouldn't.

Anyway, I want to experiment with not threading a single name through, but
generating sets of infinite names, partitioning them into still-disjoint sets,
and passing them down in a purely functional way.

I have two ideas for these infinite sets. One is just take an infinite list of
names. To split in two: take every other element, and you get two new infinite
lists.

The other, which I think is more promising, is an integer and an increment. To
take a new name: use the integer, increment by the increment. To split into
two: one person gets the integer and double the increment, the other gets the
incremented integer and double the increment. And it works naturally for
splitting into more than two. I think I should start with that generator.

Implement it, compare to the current technique.

Let me give it a try.

Sat Sep 22 15:04:51 EDT 2012

It's notably slower. 7 seconds up to 9. Or 11 up to 15. Or however you want
to look at it. More allocation. And it's messier too, if you ask me.

So, good to know. Let me ditch this method then.

Sat Sep 22 15:59:39 EDT 2012

I managed to speed up the generation of fresh names considerably by storing a
name itself, and incrementing that directly instead of make an integer and
showing it into a name every time. So now fresh name generation appears not to
be a big problem.

For BCL3, the big problem now is elaboration.

For Sudoku... I think it's too small. But most time is spent in check.

So, the thing about sharing is...

The whole point of sharing is to improve performance. If it doesn't improve
performance... well, perhaps it's slightly useful for debugging generated
queries, but other than that, it's useless.

But! I should only be doing it if it will make a big difference in
performance.

Now, we've already said that to do sharing properly, I have to do full
elaboration regardless. So, the fastest I can make elaboration is how it is
now, without added stuff for sharing.

Which means, the only way sharing will benefit performance is in how long it
takes yices to run, or how long it takes to send commands to yices.

Which means... sharing will be important when the time for (check) or
(sendCmds) dominates, and not before then.

For BCL3, the bottleneck is still in the elaborator, so that's what I should
focus on before sharing. And because I suspect that is more likely to help
than adding the complexity of sharing, I should, for now, put off my attempts
at sharing, sad as that may seem.

But, if I do that, it means the value of Seri is really only in interpreting
datatypes, right? Because otherwise you just use a DSEL in haskell. Oh, and
making it nicer to write, in which case, template haskell would be more
appropriate?

Ah, but datatypes are important. So leave that there. And I can always add
back in sharing later on once it turns out to be the bottleneck. Nifty.

Sat Sep 22 16:55:35 EDT 2012

So... what's taking so long in the elaborator?

I don't know. I would really like more benchmarks before I focus on making it
better. The interesting things need lots of stuff though.



